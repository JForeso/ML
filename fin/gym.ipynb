{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80d5f083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gymnasium as gym\n",
    "import os\n",
    "from ale_py import ALEInterface, roms\n",
    "import time\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "import random\n",
    "from collections import deque\n",
    "from keras import Input\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf91e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03817265",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"ALE/Casino-v5\", render_mode=\"rgb_array\", mode=2)\n",
    "initial_state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3dc585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "screenshot=env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e55ac450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gary(image):\n",
    "    gar=cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
    "    resized = cv2.resize(gar, (84, 84), interpolation=cv2.INTER_AREA)\n",
    "    return resized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f2ed54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pros=gary(screenshot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06c8073b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAHGklEQVR4nO3dMYoUaRiAYWfpiZoZMJlsQAYxkg7MKpc+hXfwUh5C+wKNlxgEDUQQ0Uij2eyFUtitpat2Snme7Jey6jN6+fhpPLu7u7t7AAAPHjz4674HAGA9RAGAiAIAEQUAIgoARBQAiCgAEFEAIJupD56dnS05BwALm/JbZZsCABEFACIKAGTyncLLly+XnAOAFbApABBRACCiAEBEAYCIAgARBQAiCgBEFADI5B+vHY/HWT642+1G5+12O8t7ATidTQGAiAIAEQUAIgoAZPJF8zAMS84BwArYFACIKAAQUQAgk+8U7tOLFy9G52fPnv3r33nz5s0/ngH4lU0BgIgCABEFAPJb3Cm8evVqdH79+vUvz/x87/Dw4cNFZwL4E9kUAIgoABBRACCiAEB+i4vmnz19+vSXP3v06NHo/PHjx/9pGoA/h00BgIgCABEFAPJb3Ck8f/58dH7y5Mk9TQLwZ7MpABBRACCiAEBEAYBMvmi+vLxcco5/9O7du9H5y5cvvzzz9u3b0fnz58+j833OD/C7sCkAEFEAIKIAQCbfKVxdXS05x3/y9evXf31msxn/09Y0P8Ba2RQAiCgAEFEAIKIAQEQBgIgCABEFACIKAGTyj9cOh8MsHxyGYXS+uLiY5b0AnM6mAEBEAYCIAgCZfKew3++XnAOAFbApABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCANlMffDTp09LzgHACtgUAIgoABBRACCiAEAmXzR/+/ZtyTkAWAGbAgARBQAiCgBEFACIKAAQUQAgogBAJv9O4Xg8zvLB3W43Om+321neC8DpbAoARBQAiCgAEFEAIJMvmodhWHIOAFbApgBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBkM/XB4/E4ywd3u93ovN1uZ3kvAKezKQAQUQAgogBAJt8pDMOw5BwArIBNAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAMhm6oOXl5dLzgHACtgUAIgoABBRACCiAEAmXzRfXV0tOQcAK2BTACCiAEBEAYCIAgARBQAiCgBEFACIKACQyT9eOxwOs3xwGIbR+eLiYpb3AnA6mwIAEQUAIgoAZPKdwn6/X3IOAFbApgBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBkM/XBw+EwyweHYRidLy4uZnkvAKezKQAQUQAgogBAJt8p7Pf7JecAYAVsCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEA2Ux/88ePHknMAsAI2BQAiCgBEFACIKACQyRfN79+/X3IOAFbApgBARAGAiAIAEQUAIgoARBQAiCgAEFEAIJN/vHY8Hmf54G63G5232+0s7wXgdDYFACIKAEQUAMjkO4VhGJacA4AVsCkAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIA2Ux98Hg8zvLB3W43Om+321neC8DpbAoARBQAiCgAkMl3CsMwLDkHACtgUwAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBANlMffPz48ZJzALACNgUAIgoARBQAiCgAEFEAIKIAQEQBgIgCAJn847Xb29tZPnh9fT06n5+fz/JeAE5nUwAgogBARAGAiAIAEQUAIgoARBQAiCgAkMk/Xru5uVlyDgBWwKYAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgk/+Tndvb21k+eH19PTqfn5/P8l4ATmdTACCiAEBEAYCIAgARBQAiCgBEFACIKACQyT9eu7m5WXIOAFbApgBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBkM/XBDx8+LDkHACtgUwAgogBARAGATL5T+P79+5JzALACNgUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQBydnd3d3ffQwCwDjYFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQDyN5SjZEBtSqnsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(pros,cmap='gray')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1a469be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modl(input_shape, num_actions):\n",
    "    model= Sequential([\n",
    "        Conv2D(32, (8, 8), strides=(4, 4), activation='relu', input_shape=input_shape),\n",
    "        Conv2D(64, (4, 4), strides=(2, 2), activation='relu'),\n",
    "        Conv2D(64, (3, 3), strides=(1, 1), activation='relu'),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(num_actions, activation='linear')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-4), loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca6f553f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, action_size):\n",
    "        self.memory = deque(maxlen=100000)\n",
    "        self.action_size = action_size\n",
    "        self.model = modl((84, 84, 1), action_size)\n",
    "        self.gamma = 0.99\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_min = 0.1\n",
    "        self.epsilon_decay = 0.995\n",
    "    def act(self, state):\n",
    "        if np.random.rand()<=self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        q_values = self.model.predict(state[np.newaxis, :, :, np.newaxis], verbose=0)\n",
    "        return np.argmax(q_values[0])\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "    def replay(self, batch_size=32):\n",
    "        minibatch =random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target =reward\n",
    "            if not done:\n",
    "                next_q=np.max(self.model.predict(next_state[np.newaxis, :, :, np.newaxis], verbose=0)[0])\n",
    "                target=reward+self.gamma*next_q\n",
    "            q_values = self.model.predict(state[np.newaxis, :, :, np.newaxis], verbose=0)\n",
    "            q_values[0][action] = target\n",
    "            self.model.fit(state[np.newaxis, :, :, np.newaxis], q_values, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd659171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: 1400.0\n",
      "Episode 2: 2400.0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"ALE/Casino-v5\", render_mode=\"rgb_array\", mode=2)\n",
    "agent=DQNAgent(env.action_space.n)\n",
    "bf=[]\n",
    "br=0\n",
    "be=0\n",
    "episodes = 4000\n",
    "for e in range(episodes):\n",
    "    obs, _ = env.reset()\n",
    "    env.step(env.action_space.sample())\n",
    "    frame = screenshot\n",
    "    state = pros\n",
    "    total_reward = 0\n",
    "    done=False\n",
    "    fram=[]\n",
    "    while not done:\n",
    "        action = agent.act(state)\n",
    "        obs, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        fram.append(env.render())\n",
    "        next_state = pros\n",
    "        fram.append(screenshot)\n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        if done:\n",
    "            print(f\"Episode {e+1}: {total_reward}\")\n",
    "            if total_reward>br:\n",
    "                br=total_reward\n",
    "                bf=fram\n",
    "            break\n",
    "    if len(agent.memory) > 1000:\n",
    "        agent.replay(32)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881e4bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6282fc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play():\n",
    "    env = gym.make(\"ALE/Casino-v5\", render_mode=\"human\", mode=2)\n",
    "    state, _ = env.reset()\n",
    "    state = gary(state)\n",
    "    state = np.expand_dims(state, axis=-1)  # Add channel dimension\n",
    "    state = np.expand_dims(state, axis=0)   # Add batch dimension\n",
    "    \n",
    "    total_reward = 0\n",
    "    while True:\n",
    "        # Get Q-values and choose best action\n",
    "        q_values = model.predict(state, verbose=0)\n",
    "        action = np.argmax(q_values[0])\n",
    "        \n",
    "        # Take action\n",
    "        next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        \n",
    "        # Prepare next state\n",
    "        next_state = gary(next_state)\n",
    "        next_state = np.expand_dims(next_state, axis=-1)\n",
    "        next_state = np.expand_dims(next_state, axis=0)\n",
    "        \n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        \n",
    "        if done:\n",
    "            print(f\"Game Over! Total reward: {total_reward}\")\n",
    "            break\n",
    "            \n",
    "    env.close()\n",
    "\n",
    "# Run the game\n",
    "if __name__ == \"__main__\":\n",
    "    play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d2f9fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
